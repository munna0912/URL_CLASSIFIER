{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58a00ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # this appends the parent directory to the sys.path list\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from nltk.util import ngrams\n",
    "import itertools\n",
    "from Utils import DataProcessing, FeatureCreation, Model\n",
    "N_for_NGram = 3\n",
    "Sequence_length = 200\n",
    "epochs = 2\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966dc43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d00d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "url_dataframe = pd.read_csv(\"../dataset/df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9069262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(url_dataframe, test_size=0.20, stratify=url_dataframe['type'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.20, stratify=train_df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71caf9f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "Batch_Size = BATCH_SIZE\n",
    "max_tokens = 25000\n",
    "steps_per_epoch = DataProcessing.steps_per_epoch(train_df, Batch_Size)\n",
    "validation_steps = DataProcessing.steps_per_epoch(val_df, Batch_Size)\n",
    "train_ds = DataProcessing.process_train_data(train_df,Batch_Size)\n",
    "Vectorize_Layer = tf.keras.layers.TextVectorization(standardize='lower_and_strip_punctuation',\n",
    "                                                   split=\"character\",\n",
    "                                                   ngrams=(N_for_NGram,),\n",
    "                                                   output_mode='int',\n",
    "                                                  #  max_tokens = max_tokens,\n",
    "                                                   output_sequence_length=Sequence_length)\n",
    "\n",
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = train_ds.map(lambda x,z: x[0])\n",
    "Vectorize_Layer.adapt(train_text)\n",
    "train_ds = train_ds.unbatch()\n",
    "train_ds = train_ds.shuffle(10000)\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.batch(Batch_Size)\n",
    "train_ds = train_ds.map(lambda x, z: DataProcessing.vectorize_text(x[0],x[1],z,Vectorize_Layer))\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa450ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = DataProcessing.process_data(val_df,Batch_Size,Vectorize_Layer)\n",
    "test_ds = DataProcessing.process_data(test_df,Batch_Size,Vectorize_Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e770cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = len(Vectorize_Layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda1641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = Model.create_model(Sequence_length, max_tokens, 18)\n",
    "    print(model.summary())\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience=40, monitor='val_loss', mode='min', restore_best_weights=True)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'],steps_per_execution = 64,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d92669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d154116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import Evaluation\n",
    "result = Evaluation.evaluate_model(model, test_ds, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f150b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
